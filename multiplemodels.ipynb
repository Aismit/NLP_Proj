{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re, string, sklearn, pickle, json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble, feature_extraction, linear_model, pipeline, metrics, naive_bayes, neural_network, discriminant_analysis, svm\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "import keras\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras import Sequential\n",
    "from sklearn import model_selection\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import keras.layers\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(string, var = False):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"removes bullet points\"\"\"\n",
    "    string = re.sub(\"\\\\u2022\", \"\", string) \n",
    "    string = re.sub(\"\\\\u00b7\", \"\", string)\n",
    "    \n",
    "    \"\"\"removes numbers\"\"\"\n",
    "    string = re.sub(r\"[0-9]\",\"\", string)\n",
    "    \n",
    "    \"\"\"removes punctuation and other symbols\"\"\"\n",
    "    filters='!\"\\#$%&()*+-/:;,<=>?@[\\\\]^`{|}~\\t\\n'\n",
    "    translate_dict = dict((c, \" \") for c in filters)\n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    filters2='.'\n",
    "    translate_dict2 = dict((c, \"_\") for c in filters2)\n",
    "    translate_map2 = str.maketrans(translate_dict2)\n",
    "    string = string.translate(translate_map)\n",
    "    string = string.translate(translate_map2)\n",
    "    \n",
    "    \"\"\"removes unnecessary spaces\"\"\"\n",
    "    string = re.sub('\\s+', ' ', string).strip()\n",
    "    return string.strip() if var else string.strip().lower()\n",
    "\n",
    "def generate_ngrams(s, n):\n",
    "    # Convert to lowercases\n",
    "    s = s.lower()\n",
    "    \n",
    "    # Replace all none alphanumeric characters with spaces\n",
    "    #s = re.sub(r'[^a-zA-Z0-9\\s]', '', s)\n",
    "    \n",
    "    # Break sentence in the token, remove empty tokens\n",
    "    tokens = [token for token in list(s) if token != \"\"]\n",
    "    # Use the zip function to help us generate n-grams\n",
    "    # Concatentate the tokens into ngrams and return\n",
    "    ngrams = [tokens[i:i+n] for i in range(len(tokens)-n + 1)]\n",
    "    return [\"\".join(ngram) for ngram in ngrams]\n",
    "\n",
    "def generate_list(s,list_n):\n",
    "    ret = []\n",
    "    for elem in list_n:\n",
    "        ret += generate_ngrams(s,elem)\n",
    "    return ret\n",
    "\n",
    "def flatten(x):\n",
    "    t = []\n",
    "    for elem in x:\n",
    "        curr = \" \".join(elem)\n",
    "        t+= [curr]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lacus class fames</td>\n",
       "      <td>lorem</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>στην Πλατεία του</td>\n",
       "      <td>el</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>מפני שטעו לחשוב</td>\n",
       "      <td>he</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>• Florida •</td>\n",
       "      <td>da</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>. Siehe auch : Liste der Landschaften in Nordr...</td>\n",
       "      <td>de</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Сицзян ) расположен</td>\n",
       "      <td>ru</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>. Deshalb wird</td>\n",
       "      <td>de</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Uí Fiachrach · Uí Briúin · Uí Néill · Síl</td>\n",
       "      <td>hu</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>v srednjeveški latinščini</td>\n",
       "      <td>sl</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>menjadi embrio .</td>\n",
       "      <td>id</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>prevalentemente su testo</td>\n",
       "      <td>it</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Anversa 1920 ·</td>\n",
       "      <td>it</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Albania  •  Andora  •  Armenia  •  Austria  •...</td>\n",
       "      <td>pl</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>acima , os</td>\n",
       "      <td>pt</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Krst pri Savici</td>\n",
       "      <td>sl</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>čeprav so mu domači in strici duhovniki odtego...</td>\n",
       "      <td>sl</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>; den lovgivende makt , som ligger hos monarke...</td>\n",
       "      <td>no</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>advertisement addressed to members of the Hous...</td>\n",
       "      <td>ru</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>, Java eta sistema eragile modernoak . ASCII k...</td>\n",
       "      <td>eu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Institut Verdaguer )</td>\n",
       "      <td>ca</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Minangkabau ( Jamee</td>\n",
       "      <td>id</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>soviéticas excepto Georgia , inclusive las 3 r...</td>\n",
       "      <td>es</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>адносна стварэння сумеснага</td>\n",
       "      <td>be</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ser calibrados cunha</td>\n",
       "      <td>gl</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>u društvu i životu čovjeka . Martin Luther pos...</td>\n",
       "      <td>sh</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>kalırsanız elimden gelen</td>\n",
       "      <td>tr</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>poveikio aplinkai pasekmių . Pasirenkant ekspl...</td>\n",
       "      <td>lt</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>. În timpul</td>\n",
       "      <td>ro</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Portuqaliyadan çoxlu sayda</td>\n",
       "      <td>az</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>이력서가 촬영부가 아닌</td>\n",
       "      <td>ko</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125361</th>\n",
       "      <td>, μπορούμε να τον συμπεριλάβουμε στους αγνωστι...</td>\n",
       "      <td>el</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125362</th>\n",
       "      <td>แน</td>\n",
       "      <td>th</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125363</th>\n",
       "      <td>اليمن إذ كانت</td>\n",
       "      <td>ar</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125364</th>\n",
       "      <td>Planinis ūkis pasaulyje</td>\n",
       "      <td>lt</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125365</th>\n",
       "      <td>„Vaterland“ | Block</td>\n",
       "      <td>de</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125366</th>\n",
       "      <td>javno dostupan ( za kompajlirani jezik ) . Slo...</td>\n",
       "      <td>sh</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125367</th>\n",
       "      <td>I will tear it out of the hand of your son . H...</td>\n",
       "      <td>en</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125368</th>\n",
       "      <td>gintatag-iyahan o gin-uukyan . Pero an kahubad...</td>\n",
       "      <td>war</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125369</th>\n",
       "      <td>ein tredel av</td>\n",
       "      <td>nn</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125370</th>\n",
       "      <td>etter å ha blitt undertrykt av Tito i mange år</td>\n",
       "      <td>no</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125371</th>\n",
       "      <td>qabul qilingan va</td>\n",
       "      <td>uz</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125372</th>\n",
       "      <td>Например , Ню Йорк ( градът ) е център на</td>\n",
       "      <td>bg</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125373</th>\n",
       "      <td>на одноимённом полуострове</td>\n",
       "      <td>ru</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125374</th>\n",
       "      <td>kompatibilne sa određenim</td>\n",
       "      <td>sh</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125375</th>\n",
       "      <td>Inter la riveroj</td>\n",
       "      <td>eo</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125376</th>\n",
       "      <td>innanfor eit emne</td>\n",
       "      <td>nn</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125377</th>\n",
       "      <td>kalitate handiko behi</td>\n",
       "      <td>eu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125378</th>\n",
       "      <td>เมษ</td>\n",
       "      <td>th</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125379</th>\n",
       "      <td>egyik ágát képviselik</td>\n",
       "      <td>hu</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125380</th>\n",
       "      <td>империи . В</td>\n",
       "      <td>ru</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125381</th>\n",
       "      <td>: [ 10 ]</td>\n",
       "      <td>la</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125382</th>\n",
       "      <td>stvaralac ) , jer je greškom smatrao da je kis...</td>\n",
       "      <td>hr</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125383</th>\n",
       "      <td>Созопол , в</td>\n",
       "      <td>bg</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125384</th>\n",
       "      <td>· İrlanda · İspanya · İsrail · İsveç · İsviçre...</td>\n",
       "      <td>tr</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125385</th>\n",
       "      <td>Citizen Army (</td>\n",
       "      <td>nn</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125386</th>\n",
       "      <td>, armen-stila barbekuo</td>\n",
       "      <td>eo</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125387</th>\n",
       "      <td>, although Ernie</td>\n",
       "      <td>en</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125388</th>\n",
       "      <td>州 （</td>\n",
       "      <td>ja</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125389</th>\n",
       "      <td>• Սառնակունք •</td>\n",
       "      <td>hy</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125390</th>\n",
       "      <td>mit Ausnahme Großbritanniens</td>\n",
       "      <td>de</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125391 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label  label_encode\n",
       "0                                       Lacus class fames  lorem            15\n",
       "1                                        στην Πλατεία του     el            35\n",
       "2                                         מפני שטעו לחשוב     he            52\n",
       "3                                             • Florida •     da            47\n",
       "4       . Siehe auch : Liste der Landschaften in Nordr...     de            53\n",
       "5                                     Сицзян ) расположен     ru            41\n",
       "6                                          . Deshalb wird     de            53\n",
       "7               Uí Fiachrach · Uí Briúin · Uí Néill · Síl     hu            40\n",
       "8                               v srednjeveški latinščini     sl            14\n",
       "9                                        menjadi embrio .     id            28\n",
       "10                               prevalentemente su testo     it            46\n",
       "11                                         Anversa 1920 ·     it            46\n",
       "12       Albania  •  Andora  •  Armenia  •  Austria  •...     pl             7\n",
       "13                                             acima , os     pt            18\n",
       "14                                        Krst pri Savici     sl            14\n",
       "15      čeprav so mu domači in strici duhovniki odtego...     sl            14\n",
       "16      ; den lovgivende makt , som ligger hos monarke...     no            39\n",
       "17      advertisement addressed to members of the Hous...     ru            41\n",
       "18      , Java eta sistema eragile modernoak . ASCII k...     eu             0\n",
       "19                                   Institut Verdaguer )     ca             6\n",
       "20                                    Minangkabau ( Jamee     id            28\n",
       "21      soviéticas excepto Georgia , inclusive las 3 r...     es            17\n",
       "22                            адносна стварэння сумеснага     be            34\n",
       "23                                   ser calibrados cunha     gl            10\n",
       "24      u društvu i životu čovjeka . Martin Luther pos...     sh            23\n",
       "25                               kalırsanız elimden gelen     tr            30\n",
       "26      poveikio aplinkai pasekmių . Pasirenkant ekspl...     lt            38\n",
       "27                                            . În timpul     ro             2\n",
       "28                             Portuqaliyadan çoxlu sayda     az             8\n",
       "29                                           이력서가 촬영부가 아닌     ko            44\n",
       "...                                                   ...    ...           ...\n",
       "125361  , μπορούμε να τον συμπεριλάβουμε στους αγνωστι...     el            35\n",
       "125362                                                 แน     th            49\n",
       "125363                                      اليمن إذ كانت     ar            45\n",
       "125364                            Planinis ūkis pasaulyje     lt            38\n",
       "125365                                „Vaterland“ | Block     de            53\n",
       "125366  javno dostupan ( za kompajlirani jezik ) . Slo...     sh            23\n",
       "125367  I will tear it out of the hand of your son . H...     en            55\n",
       "125368  gintatag-iyahan o gin-uukyan . Pero an kahubad...    war            50\n",
       "125369                                      ein tredel av     nn            21\n",
       "125370     etter å ha blitt undertrykt av Tito i mange år     no            39\n",
       "125371                                  qabul qilingan va     uz            37\n",
       "125372          Например , Ню Йорк ( градът ) е център на     bg            42\n",
       "125373                         на одноимённом полуострове     ru            41\n",
       "125374                          kompatibilne sa određenim     sh            23\n",
       "125375                                   Inter la riveroj     eo            33\n",
       "125376                                  innanfor eit emne     nn            21\n",
       "125377                              kalitate handiko behi     eu             0\n",
       "125378                                                เมษ     th            49\n",
       "125379                              egyik ágát képviselik     hu            40\n",
       "125380                                        империи . В     ru            41\n",
       "125381                                           : [ 10 ]     la            24\n",
       "125382  stvaralac ) , jer je greškom smatrao da je kis...     hr            20\n",
       "125383                                        Созопол , в     bg            42\n",
       "125384  · İrlanda · İspanya · İsrail · İsveç · İsviçre...     tr            30\n",
       "125385                                     Citizen Army (     nn            21\n",
       "125386                             , armen-stila barbekuo     eo            33\n",
       "125387                                   , although Ernie     en            55\n",
       "125388                                                州 （     ja            48\n",
       "125389                                     • Սառնակունք •     hy            22\n",
       "125390                       mit Ausnahme Großbritanniens     de            53\n",
       "\n",
       "[125391 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_X_data = open(\"train_X_languages_homework.json.txt\")\n",
    "X_train_content= training_X_data.readlines()\n",
    "X = [json.loads(obj)['text'] for obj in X_train_content]\n",
    "\n",
    "training_Y_data = open(\"train_y_languages_homework.json.txt\")\n",
    "Y_train_content= training_Y_data.readlines()\n",
    "Y = [json.loads(obj)['classification'] for obj in Y_train_content]\n",
    "lang_encode = dict(zip(set(Y),range(len(Y))))\n",
    "\n",
    "trainDF = pandas.DataFrame()\n",
    "trainDF['text'] = X\n",
    "trainDF['label'] = Y\n",
    "trainDF['label_encode'] = [lang_encode[i] for i in Y]\n",
    "trainDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', ngram_range=(1,3))\n",
    "tfidf_vect_ngram_chars.fit(trainDF['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = model_selection.StratifiedKFold(n_splits=8) \n",
    "# enumerate splits\n",
    "count = 1\n",
    "for train, test in kfold.split(trainDF['text'][:120000],trainDF[\"label\"][:120000]):\n",
    "    text_train = trainDF['text'].iloc[train]\n",
    "    test_valid = trainDF['text'].iloc[test]\n",
    "    y_train = trainDF[\"label\"].iloc[train]\n",
    "    y_valid = trainDF[\"label\"].iloc[test]\n",
    "    if count == 1:\n",
    "        train_seq_x1 = tfidf_vect_ngram_chars.transform(text_train) \n",
    "        valid_seq_x1 = tfidf_vect_ngram_chars.transform(test_valid) \n",
    "        train_seq_y1 = y_train\n",
    "        valid_seq_y1 = y_valid\n",
    "    if count == 2:\n",
    "        train_seq_x2 = tfidf_vect_ngram_chars.transform(text_train)\n",
    "        valid_seq_x2 = tfidf_vect_ngram_chars.transform(test_valid) \n",
    "        train_seq_y2 = y_train\n",
    "        valid_seq_y2 = y_valid\n",
    "    if count == 3:\n",
    "        train_seq_x3 = tfidf_vect_ngram_chars.transform(text_train)\n",
    "        valid_seq_x3 = tfidf_vect_ngram_chars.transform(test_valid) \n",
    "        train_seq_y3 = y_train\n",
    "        valid_seq_y3 = y_valid\n",
    "    if count == 4:\n",
    "        train_seq_x4 = tfidf_vect_ngram_chars.transform(text_train)\n",
    "        valid_seq_x4 = tfidf_vect_ngram_chars.transform(test_valid) \n",
    "        train_seq_y4 = y_train\n",
    "        valid_seq_y4 = y_valid\n",
    "    if count == 5:\n",
    "        train_seq_x5 = tfidf_vect_ngram_chars.transform(text_train)\n",
    "        valid_seq_x5 = tfidf_vect_ngram_chars.transform(test_valid) \n",
    "        train_seq_y5 = y_train\n",
    "        valid_seq_y5 = y_valid\n",
    "    if count == 6:\n",
    "        train_seq_x6 = tfidf_vect_ngram_chars.transform(text_train)\n",
    "        valid_seq_x6 = tfidf_vect_ngram_chars.transform(test_valid) \n",
    "        train_seq_y6 = y_train\n",
    "        valid_seq_y6 = y_valid\n",
    "    if count == 7:\n",
    "        train_seq_x7 = tfidf_vect_ngram_chars.transform(text_train)\n",
    "        valid_seq_x7 = tfidf_vect_ngram_chars.transform(test_valid) \n",
    "        train_seq_y7 = y_train\n",
    "        valid_seq_y7 = y_valid\n",
    "    if count == 8:\n",
    "        train_seq_x8 = tfidf_vect_ngram_chars.transform(text_train)\n",
    "        valid_seq_x8 = tfidf_vect_ngram_chars.transform(test_valid) \n",
    "        train_seq_y8 = y_train\n",
    "        valid_seq_y8 = y_valid\n",
    "    count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, label_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on test dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return predictions,metrics.accuracy_score(predictions, label_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7916527990414698"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_regression = linear_model.LogisticRegression()\n",
    "y_predictions_lr, accuracy_lr = train_model(log_regression,train_seq_x1,train_seq_y1,valid_seq_x1,valid_seq_y1)\n",
    "accuracy_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7180819180819181"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes_classifer = sklearn.naive_bayes.MultinomialNB()\n",
    "y_predictions_nb, accuracy_nb = train_model(naive_bayes_classifer,train_seq_x2,train_seq_y2,valid_seq_x2,valid_seq_y2)\n",
    "accuracy_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8109044857695128"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_c = svm.LinearSVC()\n",
    "y_predictions_svm, accuracy_svm = train_model(svm_c,train_seq_x4,train_seq_y4,valid_seq_x4,valid_seq_y4)\n",
    "accuracy_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8329000866493368"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_c = svm.LinearSVC()\n",
    "y_predictions_svm, accuracy_svm = train_model(svm_c,train_seq_x4,train_seq_y4,valid_seq_x4,valid_seq_y4)\n",
    "accuracy_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.773421350936854"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgdc = linear_model.SGDClassifier(loss='hinge',penalty='l2')\n",
    "y_predictions_sgdc, accuracy_sgdc = train_model(sgdc,train_seq_x5,train_seq_y5,valid_seq_x5,valid_seq_y5)\n",
    "accuracy_sgdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7924893276414088"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_c2 = svm.LinearSVC()\n",
    "y_predictions_svm2, accuracy_svm2 = train_model(svm_c2,train_seq_x6,train_seq_y6,valid_seq_x6,valid_seq_y6)\n",
    "accuracy_svm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.773870687929539"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_regression2 = linear_model.LogisticRegression()\n",
    "y_predictions_lr2, accuracy_lr2 = train_model(log_regression2,train_seq_x7,train_seq_y7,valid_seq_x7,valid_seq_y7)\n",
    "accuracy_lr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7525043408574863"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgdc2 = linear_model.SGDClassifier(loss='hinge',penalty='l2')\n",
    "y_predictions_sgdc2, accuracy_sgdc2 = train_model(sgdc2,train_seq_x8,train_seq_y8,valid_seq_x8,valid_seq_y8)\n",
    "accuracy_sgdc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = trainDF['text'][120000:]\n",
    "test_y = trainDF[\"label\"][120000:]\n",
    "test_x_vect = tfidf_vect_ngram_chars.transform(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_c = log_regression.predict(test_x_vect)\n",
    "y2_c = naive_bayes_classifer.predict(test_x_vect)\n",
    "y3_c = mlp.predict(test_x_vect)\n",
    "y4_c = svm_c.predict(test_x_vect)\n",
    "y5_c = sgdc.predict(test_x_vect)\n",
    "y6_c = svm_c2.predict(test_x_vect)\n",
    "y7_c = log_regression2.predict(test_x_vect)\n",
    "y8_c = sgdc2.predict(test_x_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['it', 'sl', 'fr', ..., 'zh', 'hy', 'de'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_total = []\n",
    "from statistics import mode\n",
    "for elem in range(len(y1_c)):\n",
    "    try:\n",
    "        y_total += [mode([y1_c[elem],y2_c[elem],y3_c[elem],y4_c[elem],y5_c[elem],y6_c[elem],y7_c[elem],y8_c[elem]])]\n",
    "    except statistics.StatisticsError:\n",
    "        y_total += [y8_c[elem]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_total_mod = np.array(y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7759228343535522"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_total_mod,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7365333333333334"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_c1 = svm.LinearSVC()\n",
    "y_predictions_svm1, accuracy_svm1 = train_model(svm_c1,train_seq_x1,train_seq_y1,valid_seq_x1,valid_seq_y1)\n",
    "accuracy_svm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7448"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_c2 = svm.LinearSVC()\n",
    "y_predictions_svm2, accuracy_svm2 = train_model(svm_c2,train_seq_x2,train_seq_y2,valid_seq_x2,valid_seq_y2)\n",
    "accuracy_svm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7338666666666667"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_c3 = svm.LinearSVC()\n",
    "y_predictions_svm3, accuracy_svm3 = train_model(svm_c3,train_seq_x3,train_seq_y3,valid_seq_x3,valid_seq_y3)\n",
    "accuracy_svm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7293333333333333"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_c4 = svm.LinearSVC()\n",
    "y_predictions_svm4, accuracy_svm4 = train_model(svm_c4,train_seq_x4,train_seq_y4,valid_seq_x4,valid_seq_y4)\n",
    "accuracy_svm4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7450666666666667"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_c5 = svm.LinearSVC()\n",
    "y_predictions_svm5, accuracy_svm5 = train_model(svm_c5,train_seq_x5,train_seq_y5,valid_seq_x5,valid_seq_y5)\n",
    "accuracy_svm5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7456"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_c6 = svm.LinearSVC()\n",
    "y_predictions_svm6, accuracy_svm6 = train_model(svm_c6,train_seq_x6,train_seq_y6,valid_seq_x6,valid_seq_y6)\n",
    "accuracy_svm6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7533333333333333"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_c7 = svm.LinearSVC()\n",
    "y_predictions_svm7, accuracy_svm7 = train_model(svm_c7,train_seq_x7,train_seq_y7,valid_seq_x7,valid_seq_y7)\n",
    "accuracy_svm7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7504"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_c8 = svm.LinearSVC()\n",
    "y_predictions_svm8, accuracy_svm8 = train_model(svm_c8,train_seq_x8,train_seq_y8,valid_seq_x8,valid_seq_y8)\n",
    "accuracy_svm8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = svm_c1.predict(test_x_vect)\n",
    "y2 = svm_c2.predict(test_x_vect)\n",
    "y3 = svm_c3.predict(test_x_vect)\n",
    "y4 = svm_c4.predict(test_x_vect)\n",
    "y5 = svm_c5.predict(test_x_vect)\n",
    "y6 = svm_c6.predict(test_x_vect)\n",
    "y7 = svm_c7.predict(test_x_vect)\n",
    "y8 = svm_c8.predict(test_x_vect)\n",
    "\n",
    "y_total = []\n",
    "from statistics import mode\n",
    "for elem in range(len(y1)):\n",
    "    try:\n",
    "        y_total += [mode([y1[elem],y2[elem],y3[elem],y4[elem],y5[elem],y6[elem],y7[elem],y8[elem]])]\n",
    "    except statistics.StatisticsError:\n",
    "        y_total += [y8[elem]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7761083286959748"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_total_mod = np.array(y_total)\n",
    "metrics.accuracy_score(y_total_mod,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = model_selection.KFold(n_splits=8) \n",
    "# enumerate splits\n",
    "#train, test in kfold.split(trainDF['text'][:120000],trainDF[\"label\"][:120000])\n",
    "count = 1\n",
    "for elem in range(0,8) :\n",
    "    val = 15000\n",
    "    text_train,test_valid,y_train,y_valid = model_selection.train_test_split(trainDF[\"text\"][elem*val:(elem+1)*val],trainDF[\"label\"][elem*val:(elem+1)*val])\n",
    "#     text_train = trainDF['text'].iloc[elem*val:]\n",
    "#     test_valid = trainDF['text'].iloc[test]\n",
    "#     y_train = trainDF[\"label\"].iloc[train]\n",
    "#     y_valid = trainDF[\"label\"].iloc[test]\n",
    "    if count == 1:\n",
    "        train_seq_x1 = tfidf_vect_ngram_chars.transform(text_train) \n",
    "        valid_seq_x1 = tfidf_vect_ngram_chars.transform(test_valid) \n",
    "        train_seq_y1 = y_train\n",
    "        valid_seq_y1 = y_valid\n",
    "    if count == 2:\n",
    "        train_seq_x2 = tfidf_vect_ngram_chars.transform(text_train)\n",
    "        valid_seq_x2 = tfidf_vect_ngram_chars.transform(test_valid) \n",
    "        train_seq_y2 = y_train\n",
    "        valid_seq_y2 = y_valid\n",
    "    if count == 3:\n",
    "        train_seq_x3 = tfidf_vect_ngram_chars.transform(text_train)\n",
    "        valid_seq_x3 = tfidf_vect_ngram_chars.transform(test_valid) \n",
    "        train_seq_y3 = y_train\n",
    "        valid_seq_y3 = y_valid\n",
    "    if count == 4:\n",
    "        train_seq_x4 = tfidf_vect_ngram_chars.transform(text_train)\n",
    "        valid_seq_x4 = tfidf_vect_ngram_chars.transform(test_valid) \n",
    "        train_seq_y4 = y_train\n",
    "        valid_seq_y4 = y_valid\n",
    "    if count == 5:\n",
    "        train_seq_x5 = tfidf_vect_ngram_chars.transform(text_train)\n",
    "        valid_seq_x5 = tfidf_vect_ngram_chars.transform(test_valid) \n",
    "        train_seq_y5 = y_train\n",
    "        valid_seq_y5 = y_valid\n",
    "    if count == 6:\n",
    "        train_seq_x6 = tfidf_vect_ngram_chars.transform(text_train)\n",
    "        valid_seq_x6 = tfidf_vect_ngram_chars.transform(test_valid) \n",
    "        train_seq_y6 = y_train\n",
    "        valid_seq_y6 = y_valid\n",
    "    if count == 7:\n",
    "        train_seq_x7 = tfidf_vect_ngram_chars.transform(text_train)\n",
    "        valid_seq_x7 = tfidf_vect_ngram_chars.transform(test_valid) \n",
    "        train_seq_y7 = y_train\n",
    "        valid_seq_y7 = y_valid\n",
    "    if count == 8:\n",
    "        train_seq_x8 = tfidf_vect_ngram_chars.transform(text_train)\n",
    "        valid_seq_x8 = tfidf_vect_ngram_chars.transform(test_valid) \n",
    "        train_seq_y8 = y_train\n",
    "        valid_seq_y8 = y_valid\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                         Lacus class fames\n",
       "1                                          στην Πλατεία του\n",
       "2                                           מפני שטעו לחשוב\n",
       "3                                               • Florida •\n",
       "4         . Siehe auch : Liste der Landschaften in Nordr...\n",
       "5                                       Сицзян ) расположен\n",
       "6                                            . Deshalb wird\n",
       "7                 Uí Fiachrach · Uí Briúin · Uí Néill · Síl\n",
       "8                                 v srednjeveški latinščini\n",
       "9                                          menjadi embrio .\n",
       "10                                 prevalentemente su testo\n",
       "11                                           Anversa 1920 ·\n",
       "12         Albania  •  Andora  •  Armenia  •  Austria  •...\n",
       "13                                               acima , os\n",
       "14                                          Krst pri Savici\n",
       "15        čeprav so mu domači in strici duhovniki odtego...\n",
       "16        ; den lovgivende makt , som ligger hos monarke...\n",
       "17        advertisement addressed to members of the Hous...\n",
       "18        , Java eta sistema eragile modernoak . ASCII k...\n",
       "19                                     Institut Verdaguer )\n",
       "20                                      Minangkabau ( Jamee\n",
       "21        soviéticas excepto Georgia , inclusive las 3 r...\n",
       "22                              адносна стварэння сумеснага\n",
       "23                                     ser calibrados cunha\n",
       "24        u društvu i životu čovjeka . Martin Luther pos...\n",
       "25                                 kalırsanız elimden gelen\n",
       "26        poveikio aplinkai pasekmių . Pasirenkant ekspl...\n",
       "27                                              . În timpul\n",
       "28                               Portuqaliyadan çoxlu sayda\n",
       "29                                             이력서가 촬영부가 아닌\n",
       "                                ...                        \n",
       "104970                               وفلسطين وإسرائيل وقبرص\n",
       "104971     lite om i dag . En gullbelagt bærestol ble blant\n",
       "104972    Arameans , Romans , Arabs , and Western Europe...\n",
       "104973                       xalqlardan ozroq farqlanishadi\n",
       "104974                                                    ホ\n",
       "104975                                       Γαλλία ήταν οι\n",
       "104976                                              [ 101 ]\n",
       "104977                            означе штокавско нарјечје\n",
       "104978                                                [ 6 ]\n",
       "104979                                          ناقه صالح (\n",
       "104980                                       գրեթե մեկ տարի\n",
       "104981                                                  ธอร\n",
       "104982    . Lacus massa . Etiam dolor . Lorem purus rhon...\n",
       "104983    години преди развитието на селското стопанство...\n",
       "104984                                 della Gallia celtica\n",
       "104985    Ávila · Badaxoz · Illas Baleares · Barcelona ·...\n",
       "104986    nec gravida . Nulla morbi luctus tellus etiam ...\n",
       "104987                                                  อเพ\n",
       "104988                                             FAI ) er\n",
       "104989          중견기업들이 입주하여 운영되고 있다 . 분당신도시 의 초기 도시계획을 살펴보면\n",
       "104990                                                职 内 容\n",
       "104991                                         izena . Kale\n",
       "104992                                  és eszmetörténész ,\n",
       "104993                                           • Kedang •\n",
       "104994    . Fase ini hanya didapati pada serangga yang m...\n",
       "104995                                        odio nulla id\n",
       "104996                     registreeriti tähtajaliselt 6943\n",
       "104997                                          i ] located\n",
       "104998                                            ( Cipar )\n",
       "104999    VI საუკუნეში გამოიყენებოდა შავი ზღვის სანაპირო...\n",
       "Name: text, Length: 105000, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
